# BigData Projects

This repository contains an example project using **Apache Kafka** in a **dockerized** environment, showcasing different stages of a real-time data streaming pipeline.

## Focus Areas

- **Infrastructure Orchestration**  
  Deploying a Kafka cluster and related services with Docker Compose.

- **Data Integration with Kafka Connect**  
  Source and Sink connectors to move data between external systems and Kafka.

- **Real-Time Processing with Kafka Streams**  
  Transforming, filtering, and enriching data streams in Java.

- **State Management with KTables**  
  Performing aggregations and maintaining real-time state tables.

## Technologies

- Docker & Docker Compose  
- Apache Kafka & ZooKeeper  
- Kafka Connect (Source & Sink Connectors)  
- Kafka Streams & KTables (Java)  
- Kafka CLI Tools (e.g., kafka-topics, kafka-console-consumer)

## Goal

Demonstrate a complete end-to-end streaming data workflow—from ingestion to processing to querying—using a reproducible, container-based setup.

> Additional examples and projects will be added over time as part of ongoing learning and experimentation.


